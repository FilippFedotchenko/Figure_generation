{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY4fujuTM9C9",
        "outputId": "68721a72-dc7e-4b71-901a-d9adde93dc6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import math\n",
        "import json\n",
        "import os\n",
        "from PIL import Image, ImageDraw\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "from statistics import mode\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import cv2\n",
        "from xml.etree import ElementTree as et\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import ops\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import ssd300_vgg16\n",
        "from torchvision import transforms\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import time\n",
        "import argparse\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import skimage\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "from urllib.request import urlopen\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install numpy scipy scikit-image matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tGrqpQGeDj2",
        "outputId": "a1f2f0a1-b8f5-4e13-c890-7bd4021a5478"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.8.30)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.42.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchmetrics\n",
        "from torchmetrics.detection.mean_ap import MeanAveragePrecision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyYG2Gw8eHQp",
        "outputId": "5b15f00a-66ee-4ae4-b101-7e6d598f8aaf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.1.2-py3-none-any.whl (764 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m764.8/764.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.9.0 torchmetrics-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhzwEa-Wmr8n",
        "outputId": "09f68fc5-d0a9-4cd8-a4bc-91bd47f1ab8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomShapesImageGenerator:\n",
        "    def __init__(self, width, height):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.mask = [[False] * width for _ in range(height)]\n",
        "        self.boundary_boxes = []\n",
        "        self.fig_type = []\n",
        "\n",
        "    def generate_random_color(self):\n",
        "        red = random.randint(0, 255)\n",
        "        green = random.randint(0, 255)\n",
        "        blue = random.randint(0, 255)\n",
        "        return red, green, blue\n",
        "\n",
        "    def generate_non_overlapping_coords(self): # Генерация исходных координат по оси x, y\n",
        "        for _ in range(150):\n",
        "            x = random.randint(25, self.width - 25)\n",
        "            y = random.randint(25, self.height - 25)\n",
        "\n",
        "            # Проверка, находятся ли исходные координаты в пределах размеров изображения.\n",
        "            if 0 <= int(x) < self.width and 0 <= int(y) < self.height:\n",
        "\n",
        "                # Проверка, была ли эта точка в маске ранее занята (каким-либо другим элементом).\n",
        "                if not any(self.mask[int(y)][int(x)] for i in range(int(x) - 25, int(x) + 26) for j in range(int(y) - 25, int(y) + 26)):\n",
        "                    return x, y\n",
        "\n",
        "    def check_mask_overlap(self, x, y, size, angle): # Проверка на пересечение фигур\n",
        "        # Вычисление координаты пикселей, входящих в фигуру после вращения\n",
        "        rotated_pixels = set()\n",
        "        for i in range(y - size, y + size + 1):\n",
        "            for j in range(x - size, x + size + 1):\n",
        "                rotated_x, rotated_y = self.rotate_point((j, i), (x, y), -angle)  # Определение повернутых по оси координат\n",
        "                if 0 <= rotated_x < self.width and 0 <= rotated_y < self.height:\n",
        "                    rotated_pixels.add((int(rotated_x), int(rotated_y)))\n",
        "\n",
        "        # Проверка маски только для пикселей, занимаемых фигурой после вращения\n",
        "        for rotated_x, rotated_y in rotated_pixels:\n",
        "            if self.mask[rotated_y][rotated_x]:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def plot_image(self, image):\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(image)\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    def generate_image(self):\n",
        "        image = Image.new(\"RGB\", (self.width, self.height))\n",
        "        draw = ImageDraw.Draw(image)\n",
        "        background_color = self.generate_random_color() # Генерация цвета фона\n",
        "        draw.rectangle([(0, 0), (self.width, self.height)], fill=background_color) # Создание изображения\n",
        "        num_shapes = random.randint(1, 5)\n",
        "\n",
        "        for _ in range(num_shapes):\n",
        "            shape_type = random.choice(['rhombus', 'triangle', 'circle', 'hexagon'])\n",
        "            self.fig_type.append(shape_type)\n",
        "            color = self.generate_random_color()\n",
        "            angle = random.uniform(0, 2 * math.pi)# Определение угла поворота фигуры\n",
        "            x, y = self.generate_non_overlapping_coords() # Генерация исходных координат по оси x, y\n",
        "            size = random.randint(25, min(self.width - x, self.height - y, x, y, 70)) # Определение размера фигуры\n",
        "            while self.check_mask_overlap(x, y, size, angle): # Проверка на пересечение фигур\n",
        "                x, y = self.generate_non_overlapping_coords()\n",
        "                size = 25\n",
        "\n",
        "            # Рисование фигуры и обработка маски с учетом угла\n",
        "            if shape_type == 'rhombus':\n",
        "                center_x = x\n",
        "                center_y = y  # Это координаты центра ромба\n",
        "                r1 = int(random.randint(0, 3)) # значение задающее изменчивость формы ромба\n",
        "                points = [(x, y - size), (x + size/2 + r1, y), (x, y + size), (x - size/2 - r1, y)]\n",
        "                rotated_points = [self.rotate_point(point, (center_x, center_y), angle) for point in points] # Вращение каждой точки относительно центра\n",
        "                draw.polygon(rotated_points, fill=color, outline=color) # Рисуем ромб\n",
        "\n",
        "                # Определение минимальной и максимальной координаты\n",
        "                min_x = min(rotated_x for rotated_x, _ in rotated_points)\n",
        "                max_x = max(rotated_x for rotated_x, _ in rotated_points)\n",
        "                min_y = min(rotated_y for _, rotated_y in rotated_points)\n",
        "                max_y = max(rotated_y for _, rotated_y in rotated_points)\n",
        "\n",
        "                # Создание границы вокруг ромба\n",
        "                self.boundary_boxes.append((min_x, min_y, max_x, max_y))\n",
        "                self.draw_rotated_rhombus(draw, color, x, y, size, angle, r1)\n",
        "                self.fill_mask(x, y, size)\n",
        "\n",
        "            elif shape_type == 'triangle':\n",
        "                # значения задающие изменчивость формы треугольника\n",
        "                t1 = int(random.randint(0, 3))\n",
        "                t2 = int(random.randint(0, 3))\n",
        "                t3 = int(random.randint(0, 3))\n",
        "                # Определение координаты вершин треугольника без учета вращения\n",
        "                x1, y1 = x, y - size - t1\n",
        "                x2, y2 = x + (size)/2 + t2, y\n",
        "                x3, y3 = x - (size)/2 - t3, y\n",
        "\n",
        "                # Вращение каждой вершины относительно центра\n",
        "                center_x = x\n",
        "                center_y = y\n",
        "                rotated_x1, rotated_y1 = self.rotate_point((x1, y1), (center_x, center_y), angle)\n",
        "                rotated_x2, rotated_y2 = self.rotate_point((x2, y2), (center_x, center_y), angle)\n",
        "                rotated_x3, rotated_y3 = self.rotate_point((x3, y3), (center_x, center_y), angle)\n",
        "\n",
        "                # Создание координат описывающего треугольника\n",
        "                min_x = min(rotated_x1, rotated_x2, rotated_x3)\n",
        "                max_x = max(rotated_x1, rotated_x2, rotated_x3)\n",
        "                min_y = min(rotated_y1, rotated_y2, rotated_y3)\n",
        "                max_y = max(rotated_y1, rotated_y2, rotated_y3)\n",
        "\n",
        "                # Определяем границу для треугольника\n",
        "                self.boundary_boxes.append((min_x, min_y, max_x, max_y))\n",
        "                self.draw_rotated_triangle(draw, color, x, y, size, angle, t1, t2, t3)\n",
        "\n",
        "                # Заполняем маску для текущего треугольника\n",
        "                self.fill_mask(x, y, size)\n",
        "\n",
        "            elif shape_type == 'circle':\n",
        "                self.draw_circle(draw, color, x, y, size)\n",
        "                self.fill_mask(x, y, size)\n",
        "                self.boundary_boxes.append((x - size, y - size, x + size, y + size))\n",
        "\n",
        "            elif shape_type == 'hexagon':\n",
        "                # Определяем вершины гексагона без учета вращения\n",
        "                center_x = x\n",
        "                center_y = y\n",
        "                points = []\n",
        "                for i in range(6):\n",
        "                    angle_offset = 2 * math.pi / 6 * i\n",
        "                    px = size * math.cos(angle_offset + angle)\n",
        "                    py = size * math.sin(angle_offset + angle)\n",
        "                    points.append((px, py))\n",
        "\n",
        "                # Переводим координаты обратно в систему координат изображения\n",
        "                rotated_points = [(center_x + px, center_y + py) for px, py in points]\n",
        "\n",
        "                # Определяем минимальные и максимальные значения координат\n",
        "                min_x = min(rotated_x for rotated_x, _ in rotated_points)\n",
        "                max_x = max(rotated_x for rotated_x, _ in rotated_points)\n",
        "                min_y = min(rotated_y for _, rotated_y in rotated_points)\n",
        "                max_y = max(rotated_y for _, rotated_y in rotated_points)\n",
        "\n",
        "                # Определяем границу для текущего вращенного гексагона\n",
        "                self.boundary_boxes.append((min_x, min_y, max_x, max_y))\n",
        "\n",
        "                # Рисуем вращенный гексагон\n",
        "                self.draw_hexagon(draw, color, x, y, size, angle)\n",
        "\n",
        "                # Заполняем маску для текущего гексагона\n",
        "                self.fill_mask(x, y, size)\n",
        "        return image\n",
        "\n",
        "    def draw_rotated_rhombus(self, draw, color, x, y, size, angle, t1):\n",
        "        center_x = x\n",
        "        center_y = y  # Координаты центра ромба\n",
        "        points = [(x, y - size), (x + size/2 + t1, y), (x, y + size), (x - size/2 - t1, y)]\n",
        "\n",
        "        # Вращаем каждую точку относительно центра\n",
        "        rotated_points = [self.rotate_point(point, (center_x, center_y), angle) for point in points]\n",
        "\n",
        "        # Рисуем ромб\n",
        "        draw.polygon(rotated_points, fill=color, outline=color)\n",
        "\n",
        "    def draw_rotated_triangle(self, draw, color, x, y, size, angle, t1, t2, t3):\n",
        "        center_x = x\n",
        "        center_y = y  # Координаты центра треугольника\n",
        "        points = [(x, y - size - t1), (x + size/2 + t2, y), (x - size/2 - t3, y)]\n",
        "\n",
        "        # Вращаем каждую точку относительно центра\n",
        "        rotated_points = [self.rotate_point(point, (center_x, center_y), angle) for point in points]\n",
        "\n",
        "        # Рисуем треугольник\n",
        "        draw.polygon(rotated_points, fill=color, outline=color)\n",
        "\n",
        "    def draw_circle(self, draw, color, x, y, radius):\n",
        "        draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=color, outline=color)\n",
        "\n",
        "    def draw_hexagon(self, draw, color, x, y, size, angle):\n",
        "        center_x = x\n",
        "        center_y = y\n",
        "        points = []\n",
        "        for i in range(6):\n",
        "            angle_offset = 2 * math.pi / 6 * i\n",
        "            pxx = size * math.cos(angle_offset + angle)\n",
        "            py = size * math.sin(angle_offset + angle)\n",
        "            points.append((pxx, py))\n",
        "\n",
        "        # Переводим координаты обратно в систему координат изображения\n",
        "        rotated_points = [(center_x + pxx, center_y + py) for pxx, py in points]\n",
        "\n",
        "        draw.polygon(rotated_points, fill=color, outline=color)\n",
        "\n",
        "    def draw_rotated_hexagon(self, draw, color, x, y, size, angle):\n",
        "        center_x = x\n",
        "        center_y = y  # Координаты центра гексагона\n",
        "        points = []\n",
        "        for i in range(6):\n",
        "            angle_rad = angle * 15 * math.pi\n",
        "            angle_offset = 2 * math.pi / 6 * i\n",
        "            pxxx = x + size * math.cos(angle_offset + angle_rad)\n",
        "            py = y + size * math.sin(angle_offset + angle_rad)\n",
        "            points.append((pxxx, py))\n",
        "\n",
        "        # Рисуем гексагон\n",
        "        draw.polygon(points, fill=color, outline=color)\n",
        "\n",
        "    def rotate_point(self, point, center, angle): # Функция отвечающая за вращение координат\n",
        "        x, y = point\n",
        "        cx, cy = center\n",
        "        new_x = (x - cx) * math.cos(angle) - (y - cy) * math.sin(angle) + cx\n",
        "        new_y = (x - cx) * math.sin(angle) + (y - cy) * math.cos(angle) + cy\n",
        "        return new_x, new_y\n",
        "\n",
        "    def fill_mask(self, x, y, size):\n",
        "        for i in range(y - size, y + size + 1):\n",
        "            for j in range(x - size, x + size + 1):\n",
        "                if 0 <= i < self.height and 0 <= j < self.width:\n",
        "                    self.mask[i][j] = True\n",
        "\n",
        "    def round_to_tenth(self,value):# Функция для округления значений\n",
        "        return round(value, 1)\n",
        "\n",
        "    def generate_boundary_box_params(self, id_offset):\n",
        "        params_list = []\n",
        "        for idx, (bx1, by1, bx2, by2) in enumerate(self.boundary_boxes):\n",
        "            bx1, by1, bx2, by2 = np.clip([bx1, by1, bx2, by2], 0, 256)\n",
        "            # Округляем значения до десятой доли\n",
        "            bx1, by1, bx2, by2 = int(bx1), int(by1), int(bx2), int(by2)\n",
        "            wid = bx2 - bx1\n",
        "            heig = by2 - by1\n",
        "            bx1, by1, wid, heig = map(self.round_to_tenth, (bx1, by1, wid, heig))\n",
        "\n",
        "            box_params = {\n",
        "                \"id\": id_offset + idx + 1,\n",
        "                \"name\": self.fig_type[idx],\n",
        "                \"region\": {\n",
        "                    \"origin\": {\n",
        "                        \"x\": bx1,\n",
        "                        \"y\": by1,\n",
        "                    },\n",
        "                    \"size\": {\n",
        "                        \"width\": wid,\n",
        "                        \"height\": heig\n",
        "                    }\n",
        "                }\n",
        "            }\n",
        "            params_list.append(box_params)\n",
        "        return params_list"
      ],
      "metadata": {
        "id": "SHCcUOZp7F2A"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig_folder = \"fig1\"\n",
        "os.makedirs(fig_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "json_folder = \"json1\"\n",
        "os.makedirs(json_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "Vm0MhfoAbCnd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_func(x,y):\n",
        "    id_counter = 0\n",
        "\n",
        "    for i in tqdm(range(x, y)):\n",
        "\n",
        "        # Создаем экземпляр класса\n",
        "        generator = RandomShapesImageGenerator(256, 256)\n",
        "\n",
        "        # Генерируем и сохраняем изображение\n",
        "        image = generator.generate_image()\n",
        "        image_path = os.path.join(fig_folder,  f\"{i + 1:03d}.png\")\n",
        "        image.save(image_path)\n",
        "\n",
        "        # Получаем параметры границ и сохраняем их в JSON\n",
        "        boundary_params = generator.generate_boundary_box_params(id_counter)\n",
        "        json_path = os.path.join(json_folder, f\"{i + 1:03d}.json\")\n",
        "        with open(json_path, \"w\") as json_file:\n",
        "            json.dump(boundary_params, json_file, indent=4)\n",
        "        id_counter += len(generator.boundary_boxes)"
      ],
      "metadata": {
        "id": "7aqVRnIkbCjT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_func(0,100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKVNjcJLbCck",
        "outputId": "affa0df3-18f5-4ec0-a861-759ed1f8145e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:09<00:00, 11.04it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "def create_zip_archive(archive_name, source_folders):\n",
        "    with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for folder in source_folders:\n",
        "            for root, dirs, files in os.walk(folder):\n",
        "                for file in files:\n",
        "                    file_path = os.path.join(root, file)\n",
        "                    arcname = os.path.relpath(file_path, folder)\n",
        "                    zipf.write(file_path, arcname)\n",
        "\n",
        "# Указываем папки для архивирования\n",
        "source_folders = ['fig1', 'json1']\n",
        "\n",
        "# Создаем архив\n",
        "create_zip_archive('data.zip', source_folders)"
      ],
      "metadata": {
        "id": "NsIsImJlRvHM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZHA_sufaa3-a"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_folder, json_folder, transforms=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.json_folder = json_folder\n",
        "        self.image_files = sorted([f for f in os.listdir(image_folder) if f.endswith(\".png\")])\n",
        "        self.json_files = sorted([f for f in os.listdir(json_folder) if f.endswith(\".json\")])\n",
        "        self.transforms = transforms\n",
        "        self.class_labels = ['_','hexagon', 'triangle', 'circle', 'rhombus']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = os.path.join(self.image_folder, self.image_files[idx])\n",
        "        json_path = os.path.join(self.json_folder, self.json_files[idx])\n",
        "\n",
        "        img = cv2.imread(image_path)# чтение файла\n",
        "        image = img.astype(np.float32)\n",
        "\n",
        "        with open(json_path, \"r\") as json_file:\n",
        "            json_data = json.load(json_file)\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        # Обработка данных JSON для извлечения рамок и меток.\n",
        "        for item in json_data:\n",
        "            if item[\"name\"] in self.class_labels:\n",
        "                x, y, w, h = item[\"region\"]['origin'][\"x\"], item[\"region\"]['origin'][\"y\"], item[\"region\"]['size'][\"width\"], item[\"region\"]['size'][\"height\"]\n",
        "                boxes.append([x, y, x + w, y + h])\n",
        "                labels.append(self.class_labels.index(item[\"name\"]))\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
        "            \"labels\": torch.tensor(labels, dtype=torch.int64)\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            sample = self.transforms(image = image,\n",
        "                                      bboxes = target['boxes'],\n",
        "                                      labels = labels)\n",
        "            img_res = sample['image']\n",
        "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
        "\n",
        "        return img_res, target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VYtRTw0PM86q"
      },
      "outputs": [],
      "source": [
        "def plot_img_bbox(image, target, class_labels, aug):\n",
        "    fig, ax = plt.subplots(1)\n",
        "    fig.set_size_inches(5, 5)\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = transforms.ToPILImage()(image)\n",
        "\n",
        "    ax.imshow(image)\n",
        "\n",
        "    boxes = target['boxes']\n",
        "    labels = target['labels']\n",
        "\n",
        "    for box, label_idx in zip(boxes, labels):\n",
        "        x1, y1, x2, y2 = box\n",
        "        label = class_labels[label_idx]\n",
        "\n",
        "        # Создайте описывающего прямоугольника\n",
        "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "        # Добавление названия фигуры\n",
        "        ax.text(x1, y1, label, color='r', backgroundcolor='none', fontsize=12)\n",
        "    if aug == True:\n",
        "      ax.set_title(\"Augmented Image\")\n",
        "    else:\n",
        "      ax.set_title(\"Original Image\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jGCEqhNeM8yr"
      },
      "outputs": [],
      "source": [
        "def get_model(num_classes, modelName):\n",
        "\n",
        "    # Загрузка модели\n",
        "    if modelName == 'fasterrcnn':\n",
        "        model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "        in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "        model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "        return model\n",
        "\n",
        "    if modelName == 'SSD_300':\n",
        "        model = ssd300_vgg16(pretrained = True)\n",
        "        from torchvision.models.detection.ssd import SSDClassificationHead\n",
        "        anchors = model.anchor_generator.num_anchors_per_location()\n",
        "        out_channels = [512, 1024, 512, 256, 256, 256]\n",
        "        model.head.classification_head = SSDClassificationHead(out_channels, anchors, num_classes)\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6TTgHw_gM8v1"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hht2sypAM8tA"
      },
      "outputs": [],
      "source": [
        "def get_transform(train):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.ImageCompression(quality_lower=60, quality_upper=100, p=0.5),\n",
        "            ToTensorV2(p=1.0)\n",
        "        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "    else:\n",
        "        return A.Compose([\n",
        "            ToTensorV2(p=1.0)\n",
        "        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Z7J3cigYlrnG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6807d56b-6e64-44b5-db60-1ee7959c5f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fig_files 100\n",
            "json_files 100\n"
          ]
        }
      ],
      "source": [
        "fig_folder = \"fig1\"\n",
        "json_folder = \"json1\"\n",
        "\n",
        "fig_files = sorted([f for f in os.listdir(fig_folder) if f.endswith(\".png\")])\n",
        "print('fig_files',len(fig_files))\n",
        "\n",
        "\n",
        "json_files = sorted([f for f in os.listdir(json_folder) if f.endswith(\".json\")])\n",
        "print('json_files',len(json_files))\n",
        "# Проверка количества файлов\n",
        "assert len(fig_files) == len(json_files)\n",
        "\n",
        "# Разделение на обучающую и тестовую выборки\n",
        "test_size = 0.2  # Процент тестовой выборки\n",
        "fig_train, fig_test, json_train, json_test = train_test_split(fig_files, json_files, test_size=test_size, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5rZyMz3unTPn"
      },
      "outputs": [],
      "source": [
        "# Исходные папки и папки назначения\n",
        "source_fig_folder = \"fig1\"\n",
        "source_json_folder = \"json1\"\n",
        "dest_train_fig_folder = \"train1/fig\"\n",
        "dest_train_json_folder = \"train1/json\"\n",
        "dest_test_fig_folder = \"test1/fig\"\n",
        "dest_test_json_folder = \"test1/json\"\n",
        "\n",
        "# Создание папок назначения\n",
        "os.makedirs(dest_train_fig_folder, exist_ok=True)\n",
        "os.makedirs(dest_train_json_folder, exist_ok=True)\n",
        "os.makedirs(dest_test_fig_folder, exist_ok=True)\n",
        "os.makedirs(dest_test_json_folder, exist_ok=True)\n",
        "\n",
        "# Перемещение файлов в папки назначения\n",
        "for fig_file, json_file in zip(fig_files, json_files):\n",
        "    if fig_file in fig_train:\n",
        "        shutil.copy(os.path.join(source_fig_folder, fig_file), os.path.join(dest_train_fig_folder, fig_file))\n",
        "        shutil.copy(os.path.join(source_json_folder, json_file), os.path.join(dest_train_json_folder, json_file))\n",
        "    else:\n",
        "        shutil.copy(os.path.join(source_fig_folder, fig_file), os.path.join(dest_test_fig_folder, fig_file))\n",
        "        shutil.copy(os.path.join(source_json_folder, json_file), os.path.join(dest_test_json_folder, json_file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "SApevV2-M84K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "1b430832-fc37-4788-a21e-10e8f286f6f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Создание экземпляра CustomDataset\n",
        "train = CustomDataset(image_folder= '/content/train1/fig',\n",
        "                                json_folder= '/content/train1/json',\n",
        "                                transforms = get_transform(train = True))\n",
        "\n",
        "test= CustomDataset(image_folder= '/content/test1/fig',\n",
        "                                json_folder= '/content/test1/json',\n",
        "                                transforms = get_transform(train= False))\n",
        "\n",
        "# Получение доступа к единичному примеру\n",
        "sample = train[0]\n",
        "\n",
        "image = sample[0]  # Доступ к картинке\n",
        "target = sample[1]  # Доступ к target\n",
        "\n",
        "# Визуализация картинки с описывающим прямоугольником\n",
        "plot_img_bbox(image, target, train.class_labels, aug = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Z3yg49anM8qK"
      },
      "outputs": [],
      "source": [
        "def form_loader(dataset,dataset_test ):\n",
        "  train_data, val_data = train_test_split(dataset, test_size=0.1, random_state=101)\n",
        "\n",
        "  train_loader = torch.utils.data.DataLoader(\n",
        "    train_data, batch_size = 5, shuffle=True, num_workers=2,\n",
        "    collate_fn=collate_fn)\n",
        "\n",
        "  val_loader = torch.utils.data.DataLoader(\n",
        "      val_data, batch_size = 5, shuffle=True, num_workers=2,\n",
        "      collate_fn=collate_fn, drop_last = True)\n",
        "\n",
        "  test_loader = torch.utils.data.DataLoader(\n",
        "      dataset_test, batch_size=5, shuffle=False, num_workers=2,\n",
        "      collate_fn=collate_fn, drop_last = True)\n",
        "\n",
        "  return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3yzNgWyWM8nj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fa4b51c-1882-43d1-da2b-d8227d437358"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/augmentations/functional.py:487: UserWarning: Image compression augmentation is most effective with uint8 inputs, float32 is used as input.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "train_loader_RCNN, val_loader_RCNN, test_loader_RCNN = form_loader(train, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Bk8rbBOsM8k0"
      },
      "outputs": [],
      "source": [
        "n_batches, n_batches_test = len(train_loader_RCNN), len(val_loader_RCNN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PDOZHGRqM8iD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53e02391-5506-4d73-eaf4-62553004efe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=SSD300_VGG16_Weights.COCO_V1`. You can also use `weights=SSD300_VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n",
            "100%|██████████| 136M/136M [00:00<00:00, 144MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "num_classes = 5\n",
        "modelName = 'SSD_300'\n",
        "model_RCNN = get_model(num_classes, modelName)\n",
        "model_RCNN.to(device)\n",
        "learning_rate = 1e-4\n",
        "optimizer = torch.optim.Adam(model_RCNN.parameters(), lr=learning_rate, weight_decay=0.005)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "mSI2LiPtM8fc"
      },
      "outputs": [],
      "source": [
        "def train_model(model, data_loader=None,val_loader=None, num_epoch=10):\n",
        "    metric = MeanAveragePrecision()\n",
        "    loss_accum_list = []\n",
        "    map_list = []\n",
        "    sum_image = 0\n",
        "\n",
        "    # Словарь для подсчета количества натренированных фигур\n",
        "    class_counts = {class_label: 0 for class_label in train.class_labels}\n",
        "\n",
        "    for epoch in range(1, num_epoch + 1):\n",
        "        print(f\"Starting epoch {epoch} of {num_epoch}\")\n",
        "        time_start = time.time()\n",
        "        loss_accum = 0.0\n",
        "        model.train()\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(data_loader, 1):\n",
        "            # Predict\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = model(images, targets)\n",
        "            loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Logging\n",
        "            loss_accum += loss.item()\n",
        "\n",
        "            # Обновление словаря количества натренированных фигур\n",
        "            for target in targets:\n",
        "                labels = target[\"labels\"]\n",
        "                for label in labels:\n",
        "                    class_counts[train.class_labels[label]] += 1\n",
        "\n",
        "            sum_image += len(images)\n",
        "\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        # Train losses\n",
        "        train_loss = loss_accum / n_batches\n",
        "        loss_accum_list.append(train_loss)\n",
        "\n",
        "        elapsed = time.time() - time_start\n",
        "        prefix = f\"[Epoch {epoch:2d} / {num_epoch:2d}]\"\n",
        "        print(f\"{prefix} Train loss: {train_loss:7.3f} [{elapsed:.0f} secs]\", end=' | ')\n",
        "\n",
        "        if epoch == 1:\n",
        "            torch.save(model.state_dict(), \"model_checkpoint2.pth\")\n",
        "\n",
        "        if epoch == num_epoch:\n",
        "            torch.save(model.state_dict(), \"model_checkpoint5.pth\")\n",
        "\n",
        "        preds_single = []\n",
        "        targets_single = []\n",
        "\n",
        "        for batch_idx, (images, targets) in enumerate(val_loader, 1):\n",
        "\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            targets_single.extend(targets)\n",
        "\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                pred = model(images)\n",
        "\n",
        "            preds_single.extend(pred)\n",
        "\n",
        "        metric.update(preds_single, targets_single)\n",
        "        batch_map = metric.compute()\n",
        "        map_list.append(batch_map['map'])\n",
        "        print(f\"Val mAP: {batch_map['map']}\")\n",
        "\n",
        "        clear_output(wait=True)\n",
        "        plt.figure(figsize=(16,9))\n",
        "        plt.grid(True)\n",
        "        plt.plot(loss_accum_list, label='Train loss')\n",
        "        plt.plot(map_list, label='map_list')\n",
        "        plt.legend()\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.suptitle('%d / %d - loss: %f , map: %f' % (num_epoch, epoch, loss_accum_list[-1], map_list[-1]))\n",
        "        plt.show()\n",
        "\n",
        "        print('sum_image', sum_image)\n",
        "            # Вывод суммарного количества натренированных фигур\n",
        "        for class_label, count in class_counts.items():\n",
        "            print(f\"{class_label}: {count} images\")\n",
        "\n",
        "    return model, loss_accum_list, map_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1HyyeD3_M8aD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "outputId": "afdb0108-1bd5-4829-c687-291cb66bc5c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1 of 6\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-022102cf6abf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_RCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_RCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_list_RCNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_RCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader_RCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader_RCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-21fce01b3c1d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, data_loader, val_loader, num_epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/ssd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;31m# get the features from the backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/detection/ssd.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;31m# L2 regularization + Rescaling of 1st block's feature map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mrescaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_weight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mrescaled\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epoch = 6\n",
        "model_RCNN, train_loss_RCNN, map_list_RCNN = train_model(model_RCNN, train_loader_RCNN, test_loader_RCNN, num_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iXVv637M8US"
      },
      "outputs": [],
      "source": [
        "def metric_test(model, test_loader):\n",
        "    metric = MeanAveragePrecision()\n",
        "\n",
        "    preds_single = []\n",
        "    targets_single = []\n",
        "\n",
        "    for batch_idx, (images, targets) in enumerate(test_loader, 1):\n",
        "\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        targets_single.extend(targets)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred = model(images)\n",
        "\n",
        "        preds_single.extend(pred)\n",
        "\n",
        "    metric.update(preds_single, targets_single)\n",
        "    test_map = metric.compute()\n",
        "\n",
        "    print(f\"Test mAP: {test_map['map']}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_checkpoint5.pth\")\n",
        "model_RCNN.load_state_dict(checkpoint)\n",
        "model5 =  model_RCNN"
      ],
      "metadata": {
        "id": "t5UG2fX9-BeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64jbzUOBM8RZ"
      },
      "outputs": [],
      "source": [
        "metric_test(model5, test_loader_RCNN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gliXtw0o5SoM"
      },
      "source": [
        "### Предсказание IOU для одной картинки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R7Q92296M8Oy"
      },
      "outputs": [],
      "source": [
        "def apply_threshold(prediction,threshold=0.15):\n",
        "    index = prediction['scores'] > threshold\n",
        "    pred = prediction.copy()\n",
        "    pred['boxes'] = pred['boxes'][index]\n",
        "    pred['scores'] = pred['scores'][index]\n",
        "    pred['labels'] = pred['labels'][index]\n",
        "\n",
        "    return pred\n",
        "\n",
        "def apply_threshold_batch(prediction,threshold=0.15 ):\n",
        "    preds = []\n",
        "\n",
        "    for data in prediction:\n",
        "        preds.append(apply_threshold(data, threshold))\n",
        "\n",
        "    return preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUSupgE_1yS6"
      },
      "outputs": [],
      "source": [
        "def plot_custom_img_bbox(image, prediction, target, class_labels):\n",
        "    fig, ax = plt.subplots(1)\n",
        "    fig.set_size_inches(5, 5)\n",
        "\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = transforms.ToPILImage()(image.cpu()).convert('RGB')\n",
        "\n",
        "    ax.imshow(image)\n",
        "\n",
        "    # Отрисовка предсказанных ограничивающих рамок\n",
        "    pred_boxes = prediction['boxes'].cpu().detach().numpy()\n",
        "    pred_labels = prediction['labels'].cpu().detach().numpy()\n",
        "    for box, label_idx in zip(pred_boxes, pred_labels):\n",
        "        x1, y1, x2, y2 = box\n",
        "        label = class_labels[label_idx.item()]  # Преобразуем тензор метки в скаляр\n",
        "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none', label=f'Predicted {label}')\n",
        "        ax.add_patch(rect)\n",
        "        ax.text(x1, y1, label, color='r', backgroundcolor='none', fontsize=12)\n",
        "\n",
        "    # Отрисовка действительных ограничивающих рамок (из целевых данных)\n",
        "    true_boxes = target['boxes'].cpu().detach().numpy()\n",
        "    true_labels = target['labels'].cpu().detach().numpy()\n",
        "    for box, label_idx in zip(true_boxes, true_labels):\n",
        "        x1, y1, x2, y2 = box\n",
        "        label = class_labels[label_idx.item()]  # Преобразуем тензор метки в скаляр\n",
        "        rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='g', facecolor='none', label=f'True {label}')\n",
        "        ax.add_patch(rect)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVOjdnh5tG_G"
      },
      "outputs": [],
      "source": [
        "def calculate_iou(box1, box2):\n",
        "    # box1 и box2 представлены в формате [x1, y1, x2, y2], где (x1, y1) - левый верхний угол, (x2, y2) - правый нижний угол\n",
        "    # Площадь ограничивающей рамки box1\n",
        "    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
        "\n",
        "    # Площадь ограничивающей рамки box2\n",
        "    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
        "\n",
        "    # Находим координаты области пересечения\n",
        "    x1 = max(box1[0], box2[0])\n",
        "    y1 = max(box1[1], box2[1])\n",
        "    x2 = min(box1[2], box2[2])\n",
        "    y2 = min(box1[3], box2[3])\n",
        "\n",
        "    # Проверка на пересечение\n",
        "    if x1 < x2 and y1 < y2:\n",
        "        # Площадь области пересечения\n",
        "        intersection_area = (x2 - x1) * (y2 - y1)\n",
        "        # IoU\n",
        "        iou = intersection_area / (area1 + area2 - intersection_area)\n",
        "        return iou\n",
        "    else:\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4h0mpF39aye"
      },
      "outputs": [],
      "source": [
        "def iou_func(targets, filtered_preds, i):\n",
        "    # Инициализируем список для хранения значений IoU\n",
        "    iou_values = []\n",
        "\n",
        "    # Перебираем все действительные ограничивающие рамки\n",
        "    for true_box in targets[i]['boxes'].cpu().detach().numpy():\n",
        "        max_iou = 0  # Инициализируем максимальное значение IoU для данной действительной рамки\n",
        "        for pred_box in filtered_preds[i]['boxes'].cpu().detach().numpy():\n",
        "            iou = calculate_iou(pred_box, true_box)\n",
        "            max_iou = max(max_iou, iou)  # Обновляем максимальное значение IoU\n",
        "        iou_values.append(max_iou)  # Добавляем максимальное значение IoU\n",
        "\n",
        "    # Вычисляем среднее значение IoU только для ненулевых значений\n",
        "    average_iou = sum(iou_values) / len(iou_values)\n",
        "    return average_iou"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_precision_recall(tp, fp, fn):\n",
        "    precision = tp / (tp + fp + 1e-6)  # Добавлено 1e-6 для избежания деления на ноль\n",
        "    recall = tp / (tp + fn + 1e-6)\n",
        "    return precision, recall"
      ],
      "metadata": {
        "id": "xp0Qih7sAwAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_tp_fp_fn(model, iou_threshold=0.5):\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    fn = 0\n",
        "    total_objects = 0\n",
        "\n",
        "    for i, (image, target) in enumerate(test_loader_RCNN, 1):\n",
        "        # Преобразование изображения и целевой информации на устройство\n",
        "        image = list(img.to(device) for img in image)\n",
        "        target = [{k: v.to(device) for k, v in t.items()} for t in target]\n",
        "\n",
        "        # Получение предсказаний модели\n",
        "        with torch.no_grad():\n",
        "            pred = model(image)\n",
        "            pred = apply_threshold_batch(pred, threshold=0.5)\n",
        "\n",
        "        # Итерация по предсказаниям и целям\n",
        "        for j, prediction in enumerate(pred):\n",
        "            # Истинные ограничивающие рамки и метки\n",
        "            true_boxes = target[j]['boxes'].cpu().detach().numpy()\n",
        "            true_labels = target[j]['labels'].cpu().detach().numpy()\n",
        "\n",
        "            # Предсказанные ограничивающие рамки, метки и оценки\n",
        "            pred_boxes = prediction['boxes'].cpu().detach().numpy()\n",
        "            pred_labels = prediction['labels'].cpu().detach().numpy()\n",
        "            pred_scores = prediction['scores'].cpu().detach().numpy()\n",
        "\n",
        "            # Создание массива булевых значений, где True, если IoU > порога\n",
        "            iou_matrix = np.zeros((len(true_boxes), len(pred_boxes)), dtype=bool)\n",
        "            for true_idx, true_box in enumerate(true_boxes):\n",
        "                for pred_idx, pred_box in enumerate(pred_boxes):\n",
        "                    iou = calculate_iou(true_box, pred_box)\n",
        "                    iou_matrix[true_idx, pred_idx] = iou > iou_threshold\n",
        "\n",
        "            # Вычисление TP и FP\n",
        "            used_preds = set()  # Хранит индексы предсказаний, которые уже использованы как TP или FP\n",
        "            for true_idx, true_label in enumerate(true_labels):\n",
        "                for pred_idx, pred_label in enumerate(pred_labels):\n",
        "                    if iou_matrix[true_idx, pred_idx] and true_label == pred_label and true_idx not in used_preds:\n",
        "                        tp += 1\n",
        "                        used_preds.add(true_idx)\n",
        "\n",
        "                    elif iou_matrix[true_idx, pred_idx] and true_label != pred_label and true_idx not in used_preds:\n",
        "                        fp += 1\n",
        "                        used_preds.add(true_idx)\n",
        "\n",
        "            total_objects += len(target[j]['labels'])\n",
        "            # Вычисление FN\n",
        "            fn = total_objects - fp- tp\n",
        "\n",
        "    return tp, fp, fn"
      ],
      "metadata": {
        "id": "ysIFD3mbI9GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_objects = 0\n",
        "\n",
        "for images, targets in train_loader_RCNN:\n",
        "    for target in targets:\n",
        "        total_objects += len(target['labels'])\n",
        "\n",
        "print(f\"Общее количество объектов в тестовой выборке: {total_objects}\")"
      ],
      "metadata": {
        "id": "T6qaH-s3ERhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования:\n",
        "# Замените last_batch на фактический батч данных из вашего test_loader_RCNN.\n",
        "tp, fp, fn = calculate_tp_fp_fn(model5, iou_threshold=0.75)\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"Sum: {tp+fp+fn}\")\n"
      ],
      "metadata": {
        "id": "_dl-DQ97BeCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall = calculate_precision_recall(tp, fp, fn)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "id": "zeeekfvbCHKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6_r-cHWsStL"
      },
      "outputs": [],
      "source": [
        "num_images = len(test_loader_RCNN.dataset)\n",
        "print(f\"Количество картинок в test_loader_RCNN: {num_images}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwwgJWLc_54G"
      },
      "outputs": [],
      "source": [
        "def mmm(model):\n",
        "    aver = []\n",
        "    count = 0\n",
        "    # Итерация по данным из test_loader_RCNN\n",
        "    for i, (image, target) in enumerate(test_loader_RCNN, 1):\n",
        "        # Преобразование изображения и целевой информации на устройство\n",
        "        image = list(img.to(device) for img in image)\n",
        "        target = [{k: v.to(device) for k, v in t.items()} for t in target]\n",
        "        # Получение предсказаний модели\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            pred = model5(image)\n",
        "            pred1 = apply_threshold_batch(pred, threshold=0.5)\n",
        "\n",
        "        for j in range(5):\n",
        "            # print('count', count)\n",
        "            av = iou_func(target, pred1,j)\n",
        "            aver.append(av)\n",
        "            # plot_custom_img_bbox(image[j], pred1[j], target[j], train.class_labels)\n",
        "            count += 1\n",
        "    return aver"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_my(model, index):\n",
        "    model.eval()\n",
        "    image, target = test_loader_RCNN.dataset[index]\n",
        "    pred = model([image.to(device)])\n",
        "    iou_pred = apply_threshold_batch(pred, threshold=0.5)\n",
        "    return image, iou_pred, target"
      ],
      "metadata": {
        "id": "xKisDaAW496M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aver = mmm(model5)\n",
        "max_index = aver.index(max(aver))\n",
        "min_index = aver.index(min(aver))\n",
        "med_index = aver.index(mode(aver))\n",
        "\n",
        "max_image, max_pred, max_target = iou_my(model5,max_index)\n",
        "min_image, min_pred, min_target = iou_my(model5,min_index)\n",
        "med_image, med_pred, med_target = iou_my(model5,med_index)"
      ],
      "metadata": {
        "id": "JFTmCr7SVyWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создайте распределение с помощью Seaborn\n",
        "sns.histplot(aver, bins=10, kde=True)  # Вы можете настроить количество бинов (колонок) и отображение ядерной оценки плотности\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Частота')\n",
        "plt.title('Распределение значений')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JDE_nkZh2N1X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GaIHDwkxV6-"
      },
      "outputs": [],
      "source": [
        "print('IOU - наибольшего значения', max(aver))\n",
        "plot_custom_img_bbox(max_image, max_pred[0], max_target, train.class_labels)\n",
        "\n",
        "print('IOU - наименьшего значения', min(aver))\n",
        "plot_custom_img_bbox(min_image, min_pred[0], min_target, train.class_labels)\n",
        "\n",
        "print('IOU - среднего значения', mode(aver))\n",
        "plot_custom_img_bbox(med_image, med_pred[0], med_target, train.class_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Слабая модель"
      ],
      "metadata": {
        "id": "6z2QcNba9MLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_checkpoint2.pth\")\n",
        "model_RCNN.load_state_dict(checkpoint)\n",
        "model1 =  model_RCNN\n",
        "metric_test(model1, test_loader_RCNN)"
      ],
      "metadata": {
        "id": "ohpvI3NM5jAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример использования:\n",
        "# Замените last_batch на фактический батч данных из вашего test_loader_RCNN.\n",
        "tp, fp, fn = calculate_tp_fp_fn(model5, iou_threshold=0.65)\n",
        "\n",
        "print(f\"True Positives (TP): {tp}\")\n",
        "print(f\"False Positives (FP): {fp}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n",
        "print(f\"Sum: {tp+fp+fn}\")"
      ],
      "metadata": {
        "id": "2KBChRGcnxdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision, recall = calculate_precision_recall(tp, fp, fn)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "id": "gc78xGcanyH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aver = mmm(model1)\n",
        "max_index = aver.index(max(aver))\n",
        "min_index = aver.index(min(aver))\n",
        "med_index = aver.index(mode(aver))"
      ],
      "metadata": {
        "id": "SG-vGQdaV2nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создайте распределение с помощью Seaborn\n",
        "sns.histplot(aver, bins=10, kde=True)  # Вы можете настроить количество бинов (колонок) и отображение ядерной оценки плотности\n",
        "plt.xlabel('Значения')\n",
        "plt.ylabel('Частота')\n",
        "plt.title('Распределение значений')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1hWyq0sSP0EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_image, max_pred, max_target = iou_my(model1,max_index)\n",
        "min_image, min_pred, min_target = iou_my(model1,min_index)\n",
        "med_image, med_pred, med_target = iou_my(model1,med_index)"
      ],
      "metadata": {
        "id": "8zEErEuqV3FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('IOU - наибольшего значения', max(aver))\n",
        "plot_custom_img_bbox(max_image, max_pred[0], max_target, train.class_labels)\n",
        "\n",
        "print('IOU - наименьшего значения', min(aver))\n",
        "plot_custom_img_bbox(min_image, min_pred[0], min_target, train.class_labels)\n",
        "\n",
        "print('IOU - среднего значения', mode(aver))\n",
        "plot_custom_img_bbox(med_image, med_pred[0], med_target, train.class_labels)"
      ],
      "metadata": {
        "id": "bo7zFB58W3I9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}